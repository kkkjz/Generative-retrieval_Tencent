#!/bin/bash

# MINDER ä¸€é”®è®­ç»ƒè„šæœ¬
# ä½¿ç”¨æ–¹æ³•: bash one_click_train.sh <input_json_file> [output_dir]
# ç¤ºä¾‹: bash one_click_train.sh sample_data.json ./minder_training

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥å‚æ•°
if [ $# -lt 1 ]; then
    log_error "ä½¿ç”¨æ–¹æ³•: bash $0 <input_json_file> [output_dir]"
    log_info "ç¤ºä¾‹: bash $0 sample_data.json ./minder_training"
    exit 1
fi

INPUT_JSON="$1"
OUTPUT_DIR="${2:-./minder_training}"

# æ£€æŸ¥è¾“å…¥æ–‡ä»¶
if [ ! -f "$INPUT_JSON" ]; then
    log_error "è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: $INPUT_JSON"
    exit 1
fi

log_info "å¼€å§‹MINDERä¸€é”®è®­ç»ƒæµç¨‹"
log_info "è¾“å…¥æ–‡ä»¶: $INPUT_JSON"
log_info "è¾“å‡ºç›®å½•: $OUTPUT_DIR"

# è®°å½•å¼€å§‹æ—¶é—´
START_TIME=$(date +%s)

# æ­¥éª¤1: æ£€æŸ¥å’Œå‡†å¤‡ç¯å¢ƒ
log_info "æ­¥éª¤1/8: æ£€æŸ¥å’Œå‡†å¤‡ç¯å¢ƒ"

# æ£€æŸ¥MINDERé¡¹ç›®
if [ ! -d "MINDER" ]; then
    log_warning "æœªæ‰¾åˆ°MINDERé¡¹ç›®ï¼Œæ­£åœ¨å…‹éš†..."
    git clone https://github.com/microsoft/MINDER.git
    if [ $? -ne 0 ]; then
        log_error "å…‹éš†MINDERé¡¹ç›®å¤±è´¥"
        exit 1
    fi
fi

# æ£€æŸ¥Pythonç¯å¢ƒ
if ! command -v python3 &> /dev/null; then
    log_error "æœªæ‰¾åˆ°python3ï¼Œè¯·å…ˆå®‰è£…Python 3.7+"
    exit 1
fi

# æ£€æŸ¥CUDA
if ! command -v nvidia-smi &> /dev/null; then
    log_warning "æœªæ£€æµ‹åˆ°NVIDIA GPUï¼Œè®­ç»ƒå¯èƒ½ä¼šå¾ˆæ…¢"
else
    log_info "æ£€æµ‹åˆ°NVIDIA GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader,nounits | head -1)"
fi

# å®‰è£…ç³»ç»Ÿä¾èµ–
log_info "å®‰è£…ç³»ç»Ÿä¾èµ–..."
sudo apt update -qq
sudo apt install -y swig build-essential

# ç¼–è¯‘sdsl-lite
log_info "ç¼–è¯‘sdsl-liteåº“..."
cd MINDER
if [ ! -f "res/external/sdsl-lite/lib/libsdsl.a" ]; then
    env CFLAGS='-fPIC' CXXFLAGS='-fPIC' res/external/sdsl-lite/install.sh
else
    log_info "sdsl-liteå·²ç¼–è¯‘ï¼Œè·³è¿‡"
fi
cd ..

# å®‰è£…Pythonä¾èµ–
log_info "å®‰è£…Pythonä¾èµ–..."
pip install -q -r MINDER/requirements.txt
pip install -q -e MINDER/

# å®‰è£…é¢å¤–ä¾èµ–
pip install -q tqdm fuzzywuzzy python-Levenshtein

log_success "ç¯å¢ƒå‡†å¤‡å®Œæˆ"

# æ­¥éª¤2: æ£€æŸ¥å’Œä¸‹è½½BARTæ¨¡å‹
log_info "æ­¥éª¤2/8: æ£€æŸ¥BARTæ¨¡å‹"

BART_DIR="MINDER/res/external/bart_large"
if [ ! -f "$BART_DIR/model.pt" ] || [ ! -f "$BART_DIR/dict.txt" ]; then
    log_info "BARTæ¨¡å‹ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä¸‹è½½..."
    mkdir -p "$BART_DIR"
    
    # ä¸‹è½½BARTæ¨¡å‹
    cd "$BART_DIR"
    
    # ä¸‹è½½æ¨¡å‹æ–‡ä»¶
    if [ ! -f "model.pt" ]; then
        log_info "ä¸‹è½½BARTæ¨¡å‹æ–‡ä»¶..."
        wget -q https://dl.fbaipublicfiles.com/fairseq/models/bart.large.tar.gz
        tar -xzf bart.large.tar.gz
        mv bart.large/model.pt .
        mv bart.large/dict.txt .
        rm -rf bart.large bart.large.tar.gz
    fi
    
    cd ../../..
else
    log_info "BARTæ¨¡å‹å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½"
fi

log_success "BARTæ¨¡å‹å‡†å¤‡å®Œæˆ"

# æ­¥éª¤3: æ•°æ®è½¬æ¢
log_info "æ­¥éª¤3/8: æ•°æ®è½¬æ¢"

python3 data_converter_and_trainer.py "$INPUT_JSON" --output_dir "$OUTPUT_DIR"

if [ $? -ne 0 ]; then
    log_error "æ•°æ®è½¬æ¢å¤±è´¥"
    exit 1
fi

log_success "æ•°æ®è½¬æ¢å®Œæˆ"

# è¿›å…¥è¾“å‡ºç›®å½•
cd "$OUTPUT_DIR"

# æ­¥éª¤4: ç”Ÿæˆç›‘ç£è®­ç»ƒæ•°æ®
log_info "æ­¥éª¤4/8: ç”Ÿæˆç›‘ç£è®­ç»ƒæ•°æ®"

# ç”Ÿæˆä¸‰ç§è§†è§’çš„è®­ç»ƒæ•°æ®
for split in train dev; do
    input_file="data/custom-${split}.json"
    
    for target in title span query; do
        log_info "ç”Ÿæˆ ${split} é›†çš„ ${target} æ•°æ®..."
        
        case $target in
            "title")
                n_samples=3
                mode="w"
                ;;
            "span")
                n_samples=10
                mode="a"
                ;;
            "query")
                n_samples=5
                mode="a"
                ;;
        esac
        
        cmd="python3 ../MINDER/scripts/training/make_supervised_dpr_dataset.py \
            $input_file \
            data/training_data/custom_dataset/${split} \
            --target $target \
            --mark_target \
            --mark_silver \
            --n_samples $n_samples \
            --mode $mode \
            --min_score 0.0 \
            --min_score_gold 0.0"
        
        if [ "$target" = "query" ]; then
            cmd="$cmd --pid2query data/pseudo_queries/pid2query_custom.pkl"
        fi
        
        eval $cmd
        
        if [ $? -ne 0 ]; then
            log_error "ç”Ÿæˆ ${target} æ•°æ®å¤±è´¥"
            exit 1
        fi
    done
done

log_success "ç›‘ç£è®­ç»ƒæ•°æ®ç”Ÿæˆå®Œæˆ"

# æ­¥éª¤5: ç”Ÿæˆæ— ç›‘ç£è®­ç»ƒæ•°æ®
log_info "æ­¥éª¤5/8: ç”Ÿæˆæ— ç›‘ç£è®­ç»ƒæ•°æ®"

python3 ../MINDER/scripts/training/make_generated_dataset2.py \
    data/custom_corpus.tsv \
    data/training_data/custom_dataset/unsupervised.source \
    data/training_data/custom_dataset/unsupervised.target \
    --format dpr \
    --num_samples 3 \
    --num_title_samples 1 \
    --num_query_samples 2 \
    --full_doc_n 1 \
    --mark_pretraining \
    --pid2query data/pseudo_queries/pid2query_custom.pkl

if [ $? -ne 0 ]; then
    log_error "ç”Ÿæˆæ— ç›‘ç£æ•°æ®å¤±è´¥"
    exit 1
fi

# åˆå¹¶è®­ç»ƒæ•°æ®
log_info "åˆå¹¶è®­ç»ƒæ•°æ®..."
cat data/training_data/custom_dataset/unsupervised.source >> data/training_data/custom_dataset/train.source
cat data/training_data/custom_dataset/unsupervised.target >> data/training_data/custom_dataset/train.target

log_success "æ— ç›‘ç£è®­ç»ƒæ•°æ®ç”Ÿæˆå®Œæˆ"

# æ­¥éª¤6: æ„å»ºFM-index
log_info "æ­¥éª¤6/8: æ„å»ºFM-index"

python3 ../MINDER/scripts/build_fm_index.py \
    data/custom_corpus.tsv \
    data/fm_index/custom/custom_corpus.fm_index

if [ $? -ne 0 ]; then
    log_error "æ„å»ºFM-indexå¤±è´¥"
    exit 1
fi

log_success "FM-indexæ„å»ºå®Œæˆ"

# æ­¥éª¤7: é¢„å¤„ç†æ•°æ®
log_info "æ­¥éª¤7/8: é¢„å¤„ç†æ•°æ®"

DATA_DIR="data/training_data/custom_dataset"
BART_DIR="../MINDER/res/external/bart_large"

# æ£€æŸ¥æ•°æ®æ–‡ä»¶
if [ ! -f "$DATA_DIR/train.source" ] || [ ! -f "$DATA_DIR/train.target" ]; then
    log_error "è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨"
    exit 1
fi

# ä½¿ç”¨fairseqé¢„å¤„ç†
log_info "ä½¿ç”¨fairseqé¢„å¤„ç†æ•°æ®..."
fairseq-preprocess \
    --source-lang source \
    --target-lang target \
    --trainpref $DATA_DIR/train \
    --validpref $DATA_DIR/dev \
    --destdir $DATA_DIR/bin \
    --workers 20 \
    --srcdict $BART_DIR/dict.txt \
    --tgtdict $BART_DIR/dict.txt

if [ $? -ne 0 ]; then
    log_error "æ•°æ®é¢„å¤„ç†å¤±è´¥"
    exit 1
fi

log_success "æ•°æ®é¢„å¤„ç†å®Œæˆ"

# æ­¥éª¤8: å¼€å§‹è®­ç»ƒ
log_info "æ­¥éª¤8/8: å¼€å§‹æ¨¡å‹è®­ç»ƒ"

DATA_BIN_DIR="$DATA_DIR/bin"
MODEL_DIR="checkpoints"
BART_MODEL="$BART_DIR/model.pt"

# åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
mkdir -p $MODEL_DIR

# æ£€æŸ¥GPUå†…å­˜å¹¶è°ƒæ•´æ‰¹æ¬¡å¤§å°
if command -v nvidia-smi &> /dev/null; then
    GPU_MEM=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -1)
    if [ $GPU_MEM -lt 16000 ]; then
        MAX_TOKENS=2048
        log_warning "GPUå†…å­˜è¾ƒå°ï¼Œè°ƒæ•´æ‰¹æ¬¡å¤§å°ä¸º $MAX_TOKENS"
    else
        MAX_TOKENS=4096
    fi
else
    MAX_TOKENS=1024
    log_warning "æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPUè®­ç»ƒï¼Œæ‰¹æ¬¡å¤§å°è°ƒæ•´ä¸º $MAX_TOKENS"
fi

# å¼€å§‹è®­ç»ƒ
log_info "å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦å‡ ä¸ªå°æ—¶..."
log_info "è®­ç»ƒå‚æ•°: max-tokens=$MAX_TOKENS, max-update=100000"

fairseq-train $DATA_BIN_DIR \
    --finetune-from-model $BART_MODEL \
    --arch bart_large \
    --task translation \
    --criterion label_smoothed_cross_entropy \
    --source-lang source \
    --target-lang target \
    --truncate-source \
    --label-smoothing 0.1 \
    --max-tokens $MAX_TOKENS \
    --update-freq 1 \
    --max-update 100000 \
    --required-batch-size-multiple 1 \
    --validate-interval 1000000 \
    --save-interval 1000000 \
    --save-interval-updates 5000 \
    --keep-interval-updates 3 \
    --dropout 0.1 \
    --attention-dropout 0.1 \
    --relu-dropout 0.0 \
    --weight-decay 0.01 \
    --optimizer adam \
    --adam-betas "(0.9, 0.999)" \
    --adam-eps 1e-08 \
    --clip-norm 0.1 \
    --lr-scheduler polynomial_decay \
    --lr 3e-05 \
    --total-num-update 100000 \
    --warmup-updates 500 \
    --fp16 \
    --num-workers 10 \
    --no-epoch-checkpoints \
    --share-all-embeddings \
    --layernorm-embedding \
    --share-decoder-input-output-embed \
    --skip-invalid-size-inputs-valid-test \
    --log-format json \
    --log-interval 100 \
    --patience 3 \
    --find-unused-parameters \
    --save-dir $MODEL_DIR 2>&1 | tee $MODEL_DIR/train.log

if [ $? -ne 0 ]; then
    log_error "æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—: $MODEL_DIR/train.log"
    exit 1
fi

log_success "æ¨¡å‹è®­ç»ƒå®Œæˆ"

# è®¡ç®—æ€»è€—æ—¶
END_TIME=$(date +%s)
TOTAL_TIME=$((END_TIME - START_TIME))
HOURS=$((TOTAL_TIME / 3600))
MINUTES=$(((TOTAL_TIME % 3600) / 60))
SECONDS=$((TOTAL_TIME % 60))

log_success "=== è®­ç»ƒæµç¨‹å…¨éƒ¨å®Œæˆ ==="
log_info "æ€»è€—æ—¶: ${HOURS}å°æ—¶${MINUTES}åˆ†é’Ÿ${SECONDS}ç§’"
log_info "æ¨¡å‹ä¿å­˜ä½ç½®: $(pwd)/$MODEL_DIR"
log_info "è®­ç»ƒæ—¥å¿—: $(pwd)/$MODEL_DIR/train.log"
log_info "FM-index: $(pwd)/data/fm_index/custom/custom_corpus.fm_index"

# åˆ›å»ºæµ‹è¯•è„šæœ¬
log_info "åˆ›å»ºæ¨ç†æµ‹è¯•è„šæœ¬..."
cat > test_model.sh << 'EOF'
#!/bin/bash

# æ¨¡å‹æ¨ç†æµ‹è¯•è„šæœ¬
# ä½¿ç”¨æ–¹æ³•: bash test_model.sh "æµ‹è¯•æŸ¥è¯¢"

if [ $# -lt 1 ]; then
    echo "ä½¿ç”¨æ–¹æ³•: bash $0 \"æµ‹è¯•æŸ¥è¯¢\""
    echo "ç¤ºä¾‹: bash $0 \"ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ\""
    exit 1
fi

QUERY="$1"
CHECKPOINT="checkpoints/checkpoint_best.pt"
FM_INDEX="data/fm_index/custom/custom_corpus.fm_index"
OUTPUT="test_output.json"

# åˆ›å»ºä¸´æ—¶æŸ¥è¯¢æ–‡ä»¶
echo "query_id,query" > temp_query.csv
echo "1,$QUERY" >> temp_query.csv

# è¿è¡Œæ¨ç†
TOKENIZERS_PARALLELISM=false python ../MINDER/seal/search.py \
    --topics_format dpr_qas \
    --topics temp_query.csv \
    --output_format dpr \
    --output $OUTPUT \
    --checkpoint $CHECKPOINT \
    --jobs 10 \
    --progress \
    --device cuda:0 \
    --batch_size 20 \
    --beam 15 \
    --decode_query stable \
    --fm_index $FM_INDEX

echo "æ¨ç†å®Œæˆï¼Œç»“æœä¿å­˜åœ¨: $OUTPUT"
echo "æŸ¥è¯¢: $QUERY"
echo "ç»“æœ:"
cat $OUTPUT | jq '.'

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
rm temp_query.csv
EOF

chmod +x test_model.sh

log_success "æ¨ç†æµ‹è¯•è„šæœ¬å·²åˆ›å»º: test_model.sh"
log_info "æµ‹è¯•æ¨¡å‹: bash test_model.sh \"ä½ çš„æŸ¥è¯¢\""

echo
log_success "ğŸ‰ MINDERæ¨¡å‹è®­ç»ƒå®Œæˆï¼"
echo
log_info "æ¥ä¸‹æ¥ä½ å¯ä»¥:"
log_info "1. æµ‹è¯•æ¨¡å‹: bash test_model.sh \"æµ‹è¯•æŸ¥è¯¢\""
log_info "2. æŸ¥çœ‹è®­ç»ƒæ—¥å¿—: tail -f $MODEL_DIR/train.log"
log_info "3. ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ‰¹é‡æ¨ç†"
echo